{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44196a38",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/char_set.json\n",
      "196\n",
      "{'num_of_outputs': 197, 'num_of_channels': 3, 'cnn_out_size': 512, 'input_height': 32, 'char_set_path': 'data/char_set.json'}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 96\u001b[0m\n\u001b[0;32m     93\u001b[0m     hw_state \u001b[38;5;241m=\u001b[39m safe_load\u001b[38;5;241m.\u001b[39mtorch_state(hw_path)\n\u001b[0;32m     94\u001b[0m     hw\u001b[38;5;241m.\u001b[39mload_state_dict(hw_state)\n\u001b[1;32m---> 96\u001b[0m \u001b[43mhw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m#torch.autograd.set_detect_anomaly(True)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(hw\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mpretrain_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhw\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:680\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:593\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 593\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:680\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:214\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    218\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "#MEhreen comment change warpctc_pytorch to torch.nn.CTCLoss\n",
    "#from warpctc_pytorch import CTCLoss\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "import hw\n",
    "from hw import hw_dataset\n",
    "from hw import cnn_lstm\n",
    "from hw.hw_dataset import HwDataset\n",
    "import pickle\n",
    "\n",
    "from utils.dataset_wrapper import DatasetWrapper\n",
    "from utils import safe_load\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from utils import string_utils, error_rates\n",
    "import time\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "from utils.dataset_parse import load_file_list\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "ctc_loss = []\n",
    "\n",
    "LOAD_HW = False\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "\n",
    "\n",
    "with open(\"sample_config.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.loader.SafeLoader)    \n",
    "\n",
    "print(config[\"network\"][\"hw\"]['char_set_path'])\n",
    "\n",
    "\n",
    "hw_network_config = config['network']['hw']\n",
    "pretrain_config = config['pretraining']\n",
    "\n",
    "char_set_path = hw_network_config['char_set_path']\n",
    "\n",
    "with open(char_set_path) as f:\n",
    "    char_set = json.load(f)\n",
    "\n",
    "idx_to_char = {}\n",
    "for k,v in char_set['idx_to_char'].items():\n",
    "    idx_to_char[int(k)] = v\n",
    "print(len(idx_to_char))\n",
    "\n",
    "\n",
    "config[\"network\"][\"hw\"][\"num_of_outputs\"] = len(idx_to_char) + 1\n",
    "print(config['network']['hw'])\n",
    "\n",
    "training_set_list = load_file_list(pretrain_config['training_set'])\n",
    "train_dataset = HwDataset(training_set_list,\n",
    "                          char_set['char_to_idx'], augmentation=True,\n",
    "                          img_height=hw_network_config['input_height'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size=pretrain_config['hw']['batch_size'],\n",
    "                             shuffle=True, num_workers=0, drop_last=True,\n",
    "                             collate_fn=hw_dataset.collate)\n",
    "\n",
    "batches_per_epoch = int(pretrain_config['hw']['images_per_epoch']/pretrain_config['hw']['batch_size'])\n",
    "train_dataloader = DatasetWrapper(train_dataloader, batches_per_epoch)\n",
    "\n",
    "test_set_list = load_file_list(pretrain_config['validation_set'])\n",
    "test_dataset = HwDataset(test_set_list,\n",
    "                         char_set['char_to_idx'],\n",
    "                         img_height=hw_network_config['input_height'])\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=pretrain_config['hw']['batch_size'],\n",
    "                             shuffle=False, num_workers=0,\n",
    "                             collate_fn=hw_dataset.collate)\n",
    "\n",
    "criterion = CTCLoss(blank=0, zero_infinity=True)\n",
    "\n",
    "hw = cnn_lstm.create_model(hw_network_config)\n",
    "hw.cuda()\n",
    "\n",
    "if LOAD_HW:\n",
    "\n",
    "    hw_path = os.path.join(pretrain_config['snapshot_path'], \"hw.pt\")\n",
    "    hw_state = safe_load.torch_state(hw_path)\n",
    "    hw.load_state_dict(hw_state)\n",
    "\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "optimizer = torch.optim.Adam(hw.parameters(), lr=pretrain_config['hw']['learning_rate'])\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "lowest_loss = np.inf\n",
    "cnt_since_last_improvement = 0\n",
    "for epoch in range(1000):\n",
    "    first = True\n",
    "    print (\"Epoch\", epoch)\n",
    "    sum_loss = 0.0\n",
    "    steps = 0.0\n",
    "    hw.train()\n",
    "    total_ctc_loss = 0.0\n",
    "    count = 0\n",
    "    for i, x in enumerate(train_dataloader):\n",
    "        \n",
    "        \n",
    "        line_imgs = Variable(x['line_imgs'].type(dtype), requires_grad=False)\n",
    "        labels =  Variable(x['labels'], requires_grad=False)\n",
    "        ###MEhreen\n",
    "        #print('....before', labels)\n",
    "        #labels = torch.flip(labels, [0])\n",
    "        #print('....aftr', labels)\n",
    "        ###End mehreen\n",
    "        label_lengths = Variable(x['label_lengths'], requires_grad=False)\n",
    "\n",
    "        preds = hw(line_imgs).cpu()\n",
    "        if torch.any(torch.isnan(line_imgs)):\n",
    "            bd_line_imgs = line_imgs\n",
    "            print('...NAN line_imgs: i, count', i, count)\n",
    "        if torch.any(torch.isnan(preds)):\n",
    "            bd_line_imgs = line_imgs\n",
    "            print('...NAN preds: i, count', i, count)\n",
    "            break\n",
    "        output_batch = preds.permute(1,0,2)\n",
    "        out = output_batch.data.cpu().numpy()\n",
    "\n",
    "        for i, gt_line in enumerate(x['gt']):\n",
    "            logits = out[i,...]\n",
    "            pred, raw_pred = string_utils.naive_decode(logits)\n",
    "            pred_str = string_utils.label2str_single(pred, idx_to_char, False)\n",
    "            cer = error_rates.cer(gt_line, pred_str)\n",
    "            sum_loss += cer\n",
    "            steps += 1\n",
    "\n",
    "\n",
    "        batch_size = preds.size(1)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "\n",
    "        # print \"before\"\n",
    "        loss = criterion(preds, labels, preds_size, label_lengths)\n",
    "        #print('...count', count, 'loss', loss)\n",
    "        total_ctc_loss += loss\n",
    "        #print('preds', preds)\n",
    "        #print('labels', labels)\n",
    "        #print('ctc loss, len(preds), len(labels)', loss, preds.size(), labels.size())\n",
    "        if torch.isnan(loss):\n",
    "            print('...NAN Loss, count', count)\n",
    "            #iimg = line_imgs.cpu()[0].permute(1, 2, 0)\n",
    "            #iimg = (iimg+1)*128\n",
    "            #print('....iimg', iimg.size())\n",
    "            #plt.imshow(iimg)\n",
    "            #plt.show()\n",
    "            #print('NAN LOSS i', i)\n",
    "            #print('preds.size', preds.size())\n",
    "            #print('labels length', label_lengths)\n",
    "            #print('preds', preds)\n",
    "            #print('labels', labels)\n",
    "            #print('line imgs', line_imgs)\n",
    "            break\n",
    "        # print \"after\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if torch.any(torch.isnan(hw.cnn[0].weight)):\n",
    "            print(\"NAN WEIGHT BEFORE BACKWARD\")\n",
    "        #if first:\n",
    "        #    hw2 = pickle.loads(pickle.dumps(hw))\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(hw.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        count = count + 1\n",
    "        \n",
    "    print('....ctc loss', total_ctc_loss)\n",
    "    ### MEhreen add break for one ex\n",
    "    #break\n",
    "    print( \"Train Loss\", sum_loss/steps)\n",
    "    print( \"Real Epoch\", train_dataloader.epoch)\n",
    "    train_loss.append(sum_loss/steps)\n",
    "    ctc_loss.append(total_ctc_loss.item())\n",
    "    \n",
    "    \n",
    "    \n",
    "    sum_loss = 0.0\n",
    "    steps = 0.0\n",
    "    hw.eval()\n",
    "\n",
    "    for x in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            line_imgs = Variable(x['line_imgs'].type(dtype), requires_grad=False)\n",
    "            labels =  Variable(x['labels'], requires_grad=False)\n",
    "            label_lengths = Variable(x['label_lengths'], requires_grad=False)\n",
    "\n",
    "        preds = hw(line_imgs).cpu()\n",
    "\n",
    "        output_batch = preds.permute(1,0,2)\n",
    "        out = output_batch.data.cpu().numpy()\n",
    "\n",
    "        for i, gt_line in enumerate(x['gt']):\n",
    "            logits = out[i,...]\n",
    "            pred, raw_pred = string_utils.naive_decode(logits)\n",
    "            pred_str = string_utils.label2str_single(pred, idx_to_char, False)\n",
    "            cer = error_rates.cer(gt_line, pred_str)\n",
    "            sum_loss += cer\n",
    "            steps += 1\n",
    "\n",
    "    cnt_since_last_improvement += 1\n",
    "    if lowest_loss > sum_loss/steps:\n",
    "        cnt_since_last_improvement = 0\n",
    "        lowest_loss = sum_loss/steps\n",
    "        print (\"Saving Best\")\n",
    "\n",
    "        if not os.path.exists(pretrain_config['snapshot_path']):\n",
    "            os.makedirs(pretrain_config['snapshot_path'])\n",
    "\n",
    "        torch.save(hw.state_dict(), os.path.join(pretrain_config['snapshot_path'], 'hw.pt'))\n",
    "\n",
    "    print(\"Test Loss\", sum_loss/steps, lowest_loss)\n",
    "    valid_loss.append(sum_loss/steps)\n",
    "\n",
    "    if cnt_since_last_improvement >= pretrain_config['hw']['stop_after_no_improvement'] and lowest_loss<0.9:\n",
    "        break\n",
    "print('Done ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0424a95",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "train_stat = {'train_loss': train_loss, 'ctc_loss': ctc_loss, 'valid_loss': valid_loss}\n",
    "\n",
    "\n",
    "strm = csv.writer(open(\"pretrain_hw_log.csv\", \"a\"))\n",
    "for key, val in train_stat.items():\n",
    "    strm.writerow([key, val])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
