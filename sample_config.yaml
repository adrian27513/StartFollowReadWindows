network:
  sol:
    base0: 16 #architecture dependant - don't change
    base1: 16 #architecture dependant - don't change

  lf:
    look_ahead_matrix:
    step_bias:

  hw:
    num_of_outputs: 197
    num_of_channels: 3
    cnn_out_size: 512 #architecture dependant
    input_height: 32 #architecture dependant
    char_set_path: "data/char_set.json"

  lm:
    fst_path: "lm_data/graph/HCLG.fst"
    mdl_path: "lm_data/lang_test/basic.mdl"
    words_path: "lm_data/graph/words.txt"
    phones_path: "lm_data/lang_test/phones.txt"
    beam: 8

pretraining:
  training_set:
    img_folder: ""
    json_folder: ""
    file_list: "data/train_a_training_set.json"

  validation_set:
    img_folder: ""
    json_folder: ""
    file_list: "data/train_a_validation_set.json"

  sol:
    alpha_alignment: 0.1
    alpha_backprop: 0.1
    learning_rate: 0.0001 #pyyaml bug: no scientific notation
    crop_params:
       prob_label: 0.5
       crop_size: 256
    training_rescale_range: [384, 640]
    validation_rescale_range: [512,512] #Don't validate on random range
    batch_size: 1 #During pretrain, only 45 images. If batch is 32 you would get 32 and 13 in an epoch
    images_per_epoch: 1000
    stop_after_no_improvement: 10

  lf:
    learning_rate: 0.0001 #pyyaml bug: no scientific notation
    batch_size: 1
    images_per_epoch: 1000
    stop_after_no_improvement: 10

  hw:
    learning_rate: 0.0002 #pyyaml bug: no scientific notation
    batch_size: 8
    images_per_epoch: 1000
    stop_after_no_improvement: 50

  snapshot_path: "C:/Users/Adrian/PycharmProjects/StartFollowRead/data/snapshot/init"

training:
  training_set:
    img_folder: ""
    json_folder: ""
    file_list: "data/train_b_training_set.json"

  validation_set:
    img_folder: ""
    json_folder: ""
    file_list: "data/train_b_validation_set.json"

  sol:
    alpha_alignment: 0.1
    alpha_backprop: 0.1
    learning_rate: 0.0001 #pyyaml bug: no scientific notation
    crop_params:
       prob_label: 0.5
       crop_size: 256
    training_rescale_range: [384, 640]
    validation_rescale_range: [512,512] #You should not validation on random range
    validation_subset_size: 100
    batch_size: 1
    images_per_epoch: 1000
    reset_interval: 3600 #seconds 900


  lf:
    learning_rate: 0.0001 #pyyaml bug: no scientific notation

    batch_size: 1
    refresh_interval: 3600 #seconds 900
    images_per_epoch: 1000 #batches
    validation_subset_size: 100 #images
    reset_interval: 3600 #seconds 900

  hw:
    learning_rate: 0.0002 #pyyaml bug: no scientific notation

    batch_size: 1
    refresh_interval: 3600 #seconds
    images_per_epoch: 1000 #batches
    validation_subset_size: 100 #images
    reset_interval: 3600 #seconds

  alignment:
    accept_threshold: 0.1
    sol_resize_width: 512
    metric: "cer"
    train_refresh_groups: 5

    validation_post_processing:
       sol_thresholds: [0.1,0.3,0.5,0.7,0.9]
       lf_nms_ranges: [[0,6],[0,16],[0,20]]
       lf_nms_thresholds: [0.1,0.3,0.5,0.7,0.9]

  snapshot:
    best_overall: "data/snapshot/best_overall"
    best_validation: "data/snapshot/best_validation"
    current: "data/snapshot/current"
    pretrain: "data/snapshot/init"

post_processing:
   sol_threshold: 0.1
   lf_nms_range: [0,6]
   lf_nms_threshold: 0.5
