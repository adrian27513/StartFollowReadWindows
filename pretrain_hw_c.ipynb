{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/char_set.json\n",
      "196\n",
      "{'num_of_outputs': 197, 'num_of_channels': 3, 'cnn_out_size': 512, 'input_height': 32, 'char_set_path': 'data/char_set.json'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "#MEhreen comment change warpctc_pytorch to torch.nn.CTCLoss\n",
    "#from warpctc_pytorch import CTCLoss\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "import hw\n",
    "from hw import hw_dataset\n",
    "from hw import cnn_lstm\n",
    "from hw.hw_dataset import HwDataset\n",
    "import pickle\n",
    "\n",
    "from utils.dataset_wrapper import DatasetWrapper\n",
    "from utils import safe_load\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from utils import string_utils, error_rates\n",
    "import time\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "from utils.dataset_parse import load_file_list\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "ctc_loss = []\n",
    "\n",
    "LOAD_HW = False\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "\n",
    "with open(\"sample_config.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.loader.SafeLoader)\n",
    "\n",
    "print(config[\"network\"][\"hw\"]['char_set_path'])\n",
    "\n",
    "\n",
    "hw_network_config = config['network']['hw']\n",
    "pretrain_config = config['pretraining']\n",
    "\n",
    "char_set_path = hw_network_config['char_set_path']\n",
    "\n",
    "with open(char_set_path) as f:\n",
    "    char_set = json.load(f)\n",
    "\n",
    "idx_to_char = {}\n",
    "for k,v in char_set['idx_to_char'].items():\n",
    "    idx_to_char[int(k)] = v\n",
    "print(len(idx_to_char))\n",
    "\n",
    "\n",
    "config[\"network\"][\"hw\"][\"num_of_outputs\"] = len(idx_to_char) + 1\n",
    "print(config['network']['hw'])\n",
    "\n",
    "training_set_list = load_file_list(pretrain_config['training_set'])\n",
    "train_dataset = HwDataset(training_set_list,\n",
    "                          char_set['char_to_idx'], augmentation=True,\n",
    "                          img_height=hw_network_config['input_height'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size=pretrain_config['hw']['batch_size'],\n",
    "                             shuffle=True, num_workers=0, drop_last=True,\n",
    "                             collate_fn=hw_dataset.collate)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44196a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "....ctc loss tensor(628.5752, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0170244202905683\n",
      "Real Epoch 0\n",
      "Saving Best\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 1\n",
      "....ctc loss tensor(425.4873, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 1\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 2\n",
      "....ctc loss tensor(420.8827, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 2\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 3\n",
      "....ctc loss tensor(426.1633, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 3\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 4\n",
      "....ctc loss tensor(423.0638, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 4\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 5\n",
      "....ctc loss tensor(420.1412, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 4\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 6\n",
      "....ctc loss tensor(422.1602, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 5\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 7\n",
      "....ctc loss tensor(425.2009, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 6\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 8\n",
      "....ctc loss tensor(419.8148, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 7\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 9\n",
      "....ctc loss tensor(418.6095, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 8\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 10\n",
      "....ctc loss tensor(420.7333, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 8\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 11\n",
      "....ctc loss tensor(415.9045, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 9\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 12\n",
      "....ctc loss tensor(415.3056, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 10\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 13\n",
      "....ctc loss tensor(420.1713, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 11\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 14\n",
      "....ctc loss tensor(411.2904, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 12\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 15\n",
      "....ctc loss tensor(419.4594, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 12\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 16\n",
      "....ctc loss tensor(414.7068, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 13\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 17\n",
      "....ctc loss tensor(414.1777, grad_fn=<AddBackward0>)\n",
      "Train Loss 1.0\n",
      "Real Epoch 14\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 18\n",
      "....ctc loss tensor(407.3374, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.9991192704601858\n",
      "Real Epoch 15\n",
      "Test Loss 1.0 1.0\n",
      "Epoch 19\n",
      "....ctc loss tensor(409.2966, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.999286109099023\n",
      "Real Epoch 16\n",
      "Saving Best\n",
      "Test Loss 0.9979968505690371 0.9979968505690371\n",
      "Epoch 20\n",
      "....ctc loss tensor(394.8513, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.9950699862235426\n",
      "Real Epoch 16\n",
      "Saving Best\n",
      "Test Loss 0.9912932448143981 0.9912932448143981\n",
      "Epoch 21\n",
      "....ctc loss tensor(375.9445, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.9884997460964127\n",
      "Real Epoch 17\n",
      "Saving Best\n",
      "Test Loss 0.9679960975400969 0.9679960975400969\n",
      "Epoch 22\n",
      "....ctc loss tensor(362.1379, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.975756507023249\n",
      "Real Epoch 18\n",
      "Test Loss 0.9956029038233559 0.9679960975400969\n",
      "Epoch 23\n",
      "....ctc loss tensor(353.5621, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.9405105532282199\n",
      "Real Epoch 19\n",
      "Saving Best\n",
      "Test Loss 0.9185034019771461 0.9185034019771461\n",
      "Epoch 24\n",
      "....ctc loss tensor(331.2369, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.8785326533913788\n",
      "Real Epoch 20\n",
      "Saving Best\n",
      "Test Loss 0.8842364770867398 0.8842364770867398\n",
      "Epoch 25\n",
      "....ctc loss tensor(333.2325, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.8517351944679739\n",
      "Real Epoch 20\n",
      "Test Loss 0.8940367239703381 0.8842364770867398\n",
      "Epoch 26\n",
      "....ctc loss tensor(323.3331, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.820609002115722\n",
      "Real Epoch 21\n",
      "Saving Best\n",
      "Test Loss 0.8452494177555564 0.8452494177555564\n",
      "Epoch 27\n",
      "....ctc loss tensor(313.2228, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.7942654036451654\n",
      "Real Epoch 22\n",
      "Saving Best\n",
      "Test Loss 0.823442817033507 0.823442817033507\n",
      "Epoch 28\n",
      "....ctc loss tensor(315.8939, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.7824443695421137\n",
      "Real Epoch 23\n",
      "Test Loss 0.8507187247747069 0.823442817033507\n",
      "Epoch 29\n",
      "....ctc loss tensor(301.0316, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.7499283322125901\n",
      "Real Epoch 24\n",
      "Saving Best\n",
      "Test Loss 0.7538271714309456 0.7538271714309456\n",
      "Epoch 30\n",
      "....ctc loss tensor(303.7733, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.743831828777681\n",
      "Real Epoch 24\n",
      "Saving Best\n",
      "Test Loss 0.748151673994539 0.748151673994539\n",
      "Epoch 31\n",
      "....ctc loss tensor(293.0776, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.7212688794962917\n",
      "Real Epoch 25\n",
      "Saving Best\n",
      "Test Loss 0.716758686912698 0.716758686912698\n",
      "Epoch 32\n",
      "....ctc loss tensor(286.0156, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.6936529029385468\n",
      "Real Epoch 26\n",
      "Saving Best\n",
      "Test Loss 0.6819739134345989 0.6819739134345989\n",
      "Epoch 33\n",
      "....ctc loss tensor(288.7644, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.6982890981829744\n",
      "Real Epoch 27\n",
      "Test Loss 0.7118547236895186 0.6819739134345989\n",
      "Epoch 34\n",
      "....ctc loss tensor(273.8585, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.6621448823435401\n",
      "Real Epoch 28\n",
      "Test Loss 0.6941825596212834 0.6819739134345989\n",
      "Epoch 35\n",
      "....ctc loss tensor(276.1988, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.6582106401165102\n",
      "Real Epoch 29\n",
      "Saving Best\n",
      "Test Loss 0.669781419506488 0.669781419506488\n",
      "Epoch 36\n",
      "....ctc loss tensor(268.8900, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.6418194398814876\n",
      "Real Epoch 29\n",
      "Test Loss 0.6940756860226124 0.669781419506488\n",
      "Epoch 37\n",
      "....ctc loss tensor(262.2430, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.6293963206012267\n",
      "Real Epoch 30\n",
      "Test Loss 0.7005529471820806 0.669781419506488\n",
      "Epoch 38\n",
      "....ctc loss tensor(258.3638, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.6193243994129614\n",
      "Real Epoch 31\n",
      "Test Loss 0.6882625435598462 0.669781419506488\n",
      "Epoch 39\n",
      "....ctc loss tensor(255.8511, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.6005237773961001\n",
      "Real Epoch 32\n",
      "Saving Best\n",
      "Test Loss 0.6671089282377717 0.6671089282377717\n",
      "Epoch 40\n",
      "....ctc loss tensor(248.3822, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5876190197011806\n",
      "Real Epoch 33\n",
      "Saving Best\n",
      "Test Loss 0.6336950932412304 0.6336950932412304\n",
      "Epoch 41\n",
      "....ctc loss tensor(241.9927, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.572598686860279\n",
      "Real Epoch 33\n",
      "Test Loss 0.6672389354577892 0.6336950932412304\n",
      "Epoch 42\n",
      "....ctc loss tensor(241.1616, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5685581671159541\n",
      "Real Epoch 34\n",
      "Saving Best\n",
      "Test Loss 0.6190853077264264 0.6190853077264264\n",
      "Epoch 43\n",
      "....ctc loss tensor(237.5294, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5538964551169551\n",
      "Real Epoch 35\n",
      "Test Loss 0.632215048557773 0.6190853077264264\n",
      "Epoch 44\n",
      "....ctc loss tensor(235.3263, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5534192962005158\n",
      "Real Epoch 36\n",
      "Test Loss 0.6256069955381086 0.6190853077264264\n",
      "Epoch 45\n",
      "....ctc loss tensor(234.0455, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5514567316980822\n",
      "Real Epoch 37\n",
      "Test Loss 0.6533542133301894 0.6190853077264264\n",
      "Epoch 46\n",
      "....ctc loss tensor(223.6190, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5289317870755522\n",
      "Real Epoch 37\n",
      "Saving Best\n",
      "Test Loss 0.6024421400915497 0.6024421400915497\n",
      "Epoch 47\n",
      "....ctc loss tensor(217.8404, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5160067322442132\n",
      "Real Epoch 38\n",
      "Test Loss 0.6092671960822102 0.6024421400915497\n",
      "Epoch 48\n",
      "....ctc loss tensor(213.8985, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5009919713775409\n",
      "Real Epoch 39\n",
      "Saving Best\n",
      "Test Loss 0.5759393276510233 0.5759393276510233\n",
      "Epoch 49\n",
      "....ctc loss tensor(218.4397, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.5081283835753102\n",
      "Real Epoch 40\n",
      "Test Loss 0.5875235666412382 0.5759393276510233\n",
      "Epoch 50\n",
      "....ctc loss tensor(209.6588, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.4916634877760354\n",
      "Real Epoch 41\n",
      "Test Loss 0.6173116885002033 0.5759393276510233\n",
      "Epoch 51\n",
      "....ctc loss tensor(207.1942, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.47864198177161416\n",
      "Real Epoch 41\n",
      "Test Loss 0.5798478501310347 0.5759393276510233\n",
      "Epoch 52\n",
      "....ctc loss tensor(199.4493, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.4649552201477164\n",
      "Real Epoch 42\n",
      "Saving Best\n",
      "Test Loss 0.5684878918646165 0.5684878918646165\n",
      "Epoch 53\n",
      "....ctc loss tensor(196.8283, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.46079971288023613\n",
      "Real Epoch 43\n",
      "Saving Best\n",
      "Test Loss 0.5569348353456942 0.5569348353456942\n",
      "Epoch 54\n",
      "....ctc loss tensor(192.0131, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.4441844531194917\n",
      "Real Epoch 44\n",
      "Test Loss 0.5589498441882206 0.5569348353456942\n",
      "Epoch 55\n",
      "....ctc loss tensor(193.6645, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.4467633029234573\n",
      "Real Epoch 45\n",
      "Test Loss 0.5678364437977245 0.5569348353456942\n",
      "Epoch 56\n",
      "....ctc loss tensor(189.2516, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.4422406035452079\n",
      "Real Epoch 45\n",
      "Test Loss 0.576433174785779 0.5569348353456942\n",
      "Epoch 57\n",
      "....ctc loss tensor(181.3697, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.42276851761434475\n",
      "Real Epoch 46\n",
      "Test Loss 0.5572162266486577 0.5569348353456942\n",
      "Epoch 58\n",
      "....ctc loss tensor(182.7018, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.4219063247949098\n",
      "Real Epoch 47\n",
      "Test Loss 0.5700341712411354 0.5569348353456942\n",
      "Epoch 59\n",
      "....ctc loss tensor(174.9886, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.4075921539348287\n",
      "Real Epoch 48\n",
      "Test Loss 0.5648054611884306 0.5569348353456942\n",
      "Epoch 60\n",
      "....ctc loss tensor(178.4218, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.41163272528642414\n",
      "Real Epoch 49\n",
      "Saving Best\n",
      "Test Loss 0.5431517200742259 0.5431517200742259\n",
      "Epoch 61\n",
      "....ctc loss tensor(170.4308, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.39929339077360737\n",
      "Real Epoch 49\n",
      "Test Loss 0.5852009477835477 0.5431517200742259\n",
      "Epoch 62\n",
      "....ctc loss tensor(169.6904, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.3971796493282693\n",
      "Real Epoch 50\n",
      "Test Loss 0.5884492255129548 0.5431517200742259\n",
      "Epoch 63\n",
      "....ctc loss tensor(168.2118, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.391011281546518\n",
      "Real Epoch 51\n",
      "Saving Best\n",
      "Test Loss 0.5277910837298903 0.5277910837298903\n",
      "Epoch 64\n",
      "....ctc loss tensor(159.7921, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.37626344053291144\n",
      "Real Epoch 52\n",
      "Test Loss 0.5536266270741674 0.5277910837298903\n",
      "Epoch 65\n",
      "....ctc loss tensor(159.4413, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.3688884264653603\n",
      "Real Epoch 53\n",
      "Test Loss 0.5391735377055563 0.5277910837298903\n",
      "Epoch 66\n",
      "....ctc loss tensor(158.1042, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.364947734977266\n",
      "Real Epoch 54\n",
      "Test Loss 0.5361009510620665 0.5277910837298903\n",
      "Epoch 67\n",
      "....ctc loss tensor(149.5224, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.3495235360981467\n",
      "Real Epoch 54\n",
      "Test Loss 0.5667887251106876 0.5277910837298903\n",
      "Epoch 68\n",
      "....ctc loss tensor(153.7501, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.35355974174670485\n",
      "Real Epoch 55\n",
      "Test Loss 0.547917680656057 0.5277910837298903\n",
      "Epoch 69\n",
      "....ctc loss tensor(143.2992, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.33224355715006865\n",
      "Real Epoch 56\n",
      "Test Loss 0.5281053143204952 0.5277910837298903\n",
      "Epoch 70\n",
      "....ctc loss tensor(145.8306, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.3374629164338978\n",
      "Real Epoch 57\n",
      "Test Loss 0.5445518045501092 0.5277910837298903\n",
      "Epoch 71\n",
      "....ctc loss tensor(140.6643, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.32561081280037546\n",
      "Real Epoch 58\n",
      "Saving Best\n",
      "Test Loss 0.5274252527202691 0.5274252527202691\n",
      "Epoch 72\n",
      "....ctc loss tensor(139.5955, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.3221949701990594\n",
      "Real Epoch 58\n",
      "Test Loss 0.534738669864091 0.5274252527202691\n",
      "Epoch 73\n",
      "....ctc loss tensor(138.6345, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.32509736512773446\n",
      "Real Epoch 59\n",
      "Saving Best\n",
      "Test Loss 0.5175871408736898 0.5175871408736898\n",
      "Epoch 74\n",
      "....ctc loss tensor(131.8836, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.30687142020294567\n",
      "Real Epoch 60\n",
      "Test Loss 0.5302753232128233 0.5175871408736898\n",
      "Epoch 75\n",
      "....ctc loss tensor(129.8706, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.30034439568022464\n",
      "Real Epoch 61\n",
      "Test Loss 0.5337299068997566 0.5175871408736898\n",
      "Epoch 76\n",
      "....ctc loss tensor(135.8843, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.3170577943624894\n",
      "Real Epoch 62\n",
      "Test Loss 0.5333210768661237 0.5175871408736898\n",
      "Epoch 77\n",
      "....ctc loss tensor(126.7001, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2933003332582755\n",
      "Real Epoch 62\n",
      "Test Loss 0.5185727085608682 0.5175871408736898\n",
      "Epoch 78\n",
      "....ctc loss tensor(121.7487, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.28486631128843426\n",
      "Real Epoch 63\n",
      "Test Loss 0.5239636648454532 0.5175871408736898\n",
      "Epoch 79\n",
      "....ctc loss tensor(122.4345, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.28084606487225633\n",
      "Real Epoch 64\n",
      "Test Loss 0.5362056946379259 0.5175871408736898\n",
      "Epoch 80\n",
      "....ctc loss tensor(121.6313, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.28095531244019095\n",
      "Real Epoch 65\n",
      "Test Loss 0.517608770382254 0.5175871408736898\n",
      "Epoch 81\n",
      "....ctc loss tensor(119.9707, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2766262714187588\n",
      "Real Epoch 66\n",
      "Test Loss 0.5401456788084706 0.5175871408736898\n",
      "Epoch 82\n",
      "....ctc loss tensor(115.2047, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.27043889600277377\n",
      "Real Epoch 66\n",
      "Test Loss 0.5216150112606166 0.5175871408736898\n",
      "Epoch 83\n",
      "....ctc loss tensor(114.2553, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.26543038758475557\n",
      "Real Epoch 67\n",
      "Saving Best\n",
      "Test Loss 0.5175494088514719 0.5175494088514719\n",
      "Epoch 84\n",
      "....ctc loss tensor(110.5144, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.25425873602295423\n",
      "Real Epoch 68\n",
      "Test Loss 0.5494839926497629 0.5175494088514719\n",
      "Epoch 85\n",
      "....ctc loss tensor(109.4097, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2571257616087731\n",
      "Real Epoch 69\n",
      "Saving Best\n",
      "Test Loss 0.5070537933600685 0.5070537933600685\n",
      "Epoch 86\n",
      "....ctc loss tensor(111.1949, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2596570782253163\n",
      "Real Epoch 70\n",
      "Saving Best\n",
      "Test Loss 0.5008039368837717 0.5008039368837717\n",
      "Epoch 87\n",
      "....ctc loss tensor(106.4819, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.24506744344820108\n",
      "Real Epoch 70\n",
      "Test Loss 0.536583340643245 0.5008039368837717\n",
      "Epoch 88\n",
      "....ctc loss tensor(102.7010, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.24233902358749065\n",
      "Real Epoch 71\n",
      "Test Loss 0.5335038321190245 0.5008039368837717\n",
      "Epoch 89\n",
      "....ctc loss tensor(110.2414, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2562942827704184\n",
      "Real Epoch 72\n",
      "Test Loss 0.5185703713597211 0.5008039368837717\n",
      "Epoch 90\n",
      "....ctc loss tensor(99.9543, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2335204988064565\n",
      "Real Epoch 73\n",
      "Test Loss 0.5174331962869962 0.5008039368837717\n",
      "Epoch 91\n",
      "....ctc loss tensor(96.0457, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.22335189412918896\n",
      "Real Epoch 74\n",
      "Test Loss 0.518610546621391 0.5008039368837717\n",
      "Epoch 92\n",
      "....ctc loss tensor(100.6767, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.23539471572970752\n",
      "Real Epoch 74\n",
      "Test Loss 0.5237896196058204 0.5008039368837717\n",
      "Epoch 93\n",
      "....ctc loss tensor(97.4493, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.22602736966356238\n",
      "Real Epoch 75\n",
      "Test Loss 0.5088235474800777 0.5008039368837717\n",
      "Epoch 94\n",
      "....ctc loss tensor(93.5816, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2188939457965558\n",
      "Real Epoch 76\n",
      "Test Loss 0.5105375963356471 0.5008039368837717\n",
      "Epoch 95\n",
      "....ctc loss tensor(92.7599, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.21738059292401446\n",
      "Real Epoch 77\n",
      "Test Loss 0.5011251845892403 0.5008039368837717\n",
      "Epoch 96\n",
      "....ctc loss tensor(93.5130, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2173295757673456\n",
      "Real Epoch 78\n",
      "Test Loss 0.5228677652689219 0.5008039368837717\n",
      "Epoch 97\n",
      "....ctc loss tensor(98.4412, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.229814780306892\n",
      "Real Epoch 79\n",
      "Test Loss 0.510919812622513 0.5008039368837717\n",
      "Epoch 98\n",
      "....ctc loss tensor(89.6129, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.20853493091082165\n",
      "Real Epoch 79\n",
      "Test Loss 0.5119665442870434 0.5008039368837717\n",
      "Epoch 99\n",
      "....ctc loss tensor(89.8290, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.21085061338700062\n",
      "Real Epoch 80\n",
      "Test Loss 0.5138892455632147 0.5008039368837717\n",
      "Epoch 100\n",
      "....ctc loss tensor(84.5764, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.2013285812727187\n",
      "Real Epoch 81\n",
      "Test Loss 0.5128534896535972 0.5008039368837717\n",
      "Epoch 101\n",
      "....ctc loss tensor(87.3404, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.19941204020406483\n",
      "Real Epoch 82\n",
      "Test Loss 0.5147248823133089 0.5008039368837717\n",
      "Epoch 102\n",
      "....ctc loss tensor(83.4644, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.19791182267890925\n",
      "Real Epoch 83\n",
      "Test Loss 0.515468401391248 0.5008039368837717\n",
      "Epoch 103\n",
      "....ctc loss tensor(84.0052, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.192934830392116\n",
      "Real Epoch 83\n",
      "Test Loss 0.5108012566059331 0.5008039368837717\n",
      "Epoch 104\n",
      "....ctc loss tensor(79.5409, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.18508598654779645\n",
      "Real Epoch 84\n",
      "Test Loss 0.5138299302825978 0.5008039368837717\n",
      "Epoch 105\n",
      "....ctc loss tensor(81.8893, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.1964699091557432\n",
      "Real Epoch 85\n",
      "Test Loss 0.5283649843442249 0.5008039368837717\n",
      "Epoch 106\n",
      "....ctc loss tensor(80.3033, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.18720154861033175\n",
      "Real Epoch 86\n",
      "Test Loss 0.5055758952284876 0.5008039368837717\n",
      "Epoch 107\n",
      "....ctc loss tensor(79.4907, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.18746636092978394\n",
      "Real Epoch 87\n",
      "Test Loss 0.5057953308542319 0.5008039368837717\n",
      "Epoch 108\n",
      "....ctc loss tensor(76.7843, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.1820881007690047\n",
      "Real Epoch 87\n",
      "Test Loss 0.5146846187300546 0.5008039368837717\n",
      "Epoch 109\n",
      "....ctc loss tensor(78.4844, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.18369635339793142\n",
      "Real Epoch 88\n",
      "Test Loss 0.501688071787811 0.5008039368837717\n",
      "Epoch 110\n",
      "....ctc loss tensor(77.2197, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.1823397604237769\n",
      "Real Epoch 89\n",
      "Test Loss 0.5137480458033707 0.5008039368837717\n",
      "Epoch 111\n",
      "....ctc loss tensor(75.3751, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.18058349184985475\n",
      "Real Epoch 90\n",
      "Test Loss 0.5099385710394931 0.5008039368837717\n",
      "Epoch 112\n",
      "....ctc loss tensor(74.5213, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.1761746975963461\n",
      "Real Epoch 91\n",
      "Test Loss 0.5083898785200558 0.5008039368837717\n",
      "Epoch 113\n",
      "....ctc loss tensor(73.3994, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.17282639601079045\n",
      "Real Epoch 91\n",
      "Test Loss 0.5075720763554546 0.5008039368837717\n",
      "Epoch 114\n",
      "....ctc loss tensor(70.9598, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.16754473302166623\n",
      "Real Epoch 92\n",
      "Test Loss 0.504141235328911 0.5008039368837717\n",
      "Epoch 115\n",
      "....ctc loss tensor(74.3371, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.17911709041531185\n",
      "Real Epoch 93\n",
      "Test Loss 0.5024452651020005 0.5008039368837717\n",
      "Epoch 116\n",
      "....ctc loss tensor(71.0421, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.16774519650960043\n",
      "Real Epoch 94\n",
      "Test Loss 0.5058785715125051 0.5008039368837717\n",
      "Epoch 117\n",
      "....ctc loss tensor(67.9545, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.1600677554564037\n",
      "Real Epoch 95\n",
      "Test Loss 0.5106677563506439 0.5008039368837717\n",
      "Epoch 118\n",
      "....ctc loss tensor(68.7653, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.16177447528568525\n",
      "Real Epoch 95\n",
      "Test Loss 0.519068904847644 0.5008039368837717\n",
      "Epoch 119\n",
      "....ctc loss tensor(67.1325, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.1622347573353426\n",
      "Real Epoch 96\n",
      "Test Loss 0.5155637662083653 0.5008039368837717\n",
      "Epoch 120\n",
      "....ctc loss tensor(67.1474, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.16081351857538834\n",
      "Real Epoch 97\n",
      "Test Loss 0.5124180515502144 0.5008039368837717\n",
      "Epoch 121\n",
      "....ctc loss tensor(69.0627, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.16179032353342457\n",
      "Real Epoch 98\n",
      "Test Loss 0.532513030067166 0.5008039368837717\n",
      "Epoch 122\n",
      "....ctc loss tensor(63.6704, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.15154282170342953\n",
      "Real Epoch 99\n",
      "Test Loss 0.5134137948030357 0.5008039368837717\n",
      "Epoch 123\n",
      "....ctc loss tensor(65.0243, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.15728727708948878\n",
      "Real Epoch 99\n",
      "Test Loss 0.5197254484029552 0.5008039368837717\n",
      "Epoch 124\n",
      "....ctc loss tensor(64.4681, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.15224952338760697\n",
      "Real Epoch 100\n",
      "Test Loss 0.5148252441573409 0.5008039368837717\n",
      "Epoch 125\n",
      "....ctc loss tensor(61.4947, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.14949470124448114\n",
      "Real Epoch 101\n",
      "Test Loss 0.5276525408242447 0.5008039368837717\n",
      "Epoch 126\n",
      "....ctc loss tensor(63.9416, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.15376976190534594\n",
      "Real Epoch 102\n",
      "Test Loss 0.5121806849315822 0.5008039368837717\n",
      "Epoch 127\n",
      "....ctc loss tensor(64.3246, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.14894165785145785\n",
      "Real Epoch 103\n",
      "Test Loss 0.5175948665057831 0.5008039368837717\n",
      "Epoch 128\n",
      "....ctc loss tensor(61.5808, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.14560730426478347\n",
      "Real Epoch 104\n",
      "Test Loss 0.5064335911382956 0.5008039368837717\n",
      "Epoch 129\n",
      "....ctc loss tensor(60.3915, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.14373135558172626\n",
      "Real Epoch 104\n",
      "Test Loss 0.5068231604891132 0.5008039368837717\n",
      "Epoch 130\n",
      "....ctc loss tensor(62.2754, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.14829304851639713\n",
      "Real Epoch 105\n",
      "Test Loss 0.506435465865941 0.5008039368837717\n",
      "Epoch 131\n",
      "....ctc loss tensor(59.6992, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.1455586025725433\n",
      "Real Epoch 106\n",
      "Test Loss 0.518836453192452 0.5008039368837717\n",
      "Epoch 132\n",
      "....ctc loss tensor(57.1769, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.13822529369878084\n",
      "Real Epoch 107\n",
      "Test Loss 0.5080883790498675 0.5008039368837717\n",
      "Epoch 133\n",
      "....ctc loss tensor(57.9148, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.1349353285103023\n",
      "Real Epoch 108\n",
      "Test Loss 0.5008153964946237 0.5008039368837717\n",
      "Epoch 134\n",
      "....ctc loss tensor(59.5292, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.14311787694548667\n",
      "Real Epoch 108\n",
      "Test Loss 0.5098249095139322 0.5008039368837717\n",
      "Epoch 135\n",
      "....ctc loss tensor(57.6591, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.13889481156753467\n",
      "Real Epoch 109\n",
      "Test Loss 0.5211824384607976 0.5008039368837717\n",
      "Epoch 136\n",
      "....ctc loss tensor(53.7678, grad_fn=<AddBackward0>)\n",
      "Train Loss 0.12815830403053205\n",
      "Real Epoch 110\n",
      "Test Loss 0.516128774915031 0.5008039368837717\n",
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batches_per_epoch = int(pretrain_config['hw']['images_per_epoch']/pretrain_config['hw']['batch_size'])\n",
    "train_dataloader = DatasetWrapper(train_dataloader, batches_per_epoch)\n",
    "\n",
    "test_set_list = load_file_list(pretrain_config['validation_set'])\n",
    "test_dataset = HwDataset(test_set_list,\n",
    "                         char_set['char_to_idx'],\n",
    "                         img_height=hw_network_config['input_height'])\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=pretrain_config['hw']['batch_size'],\n",
    "                             shuffle=False, num_workers=0,\n",
    "                             collate_fn=hw_dataset.collate)\n",
    "\n",
    "criterion = CTCLoss(blank=0, zero_infinity=True)\n",
    "\n",
    "hw = cnn_lstm.create_model(hw_network_config)\n",
    "hw.cuda()\n",
    "\n",
    "if LOAD_HW:\n",
    "\n",
    "    hw_path = os.path.join(pretrain_config['snapshot_path'], \"hw.pt\")\n",
    "    hw_state = safe_load.torch_state(hw_path)\n",
    "    hw.load_state_dict(hw_state)\n",
    "\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "optimizer = torch.optim.Adam(hw.parameters(), lr=pretrain_config['hw']['learning_rate'])\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "lowest_loss = np.inf\n",
    "cnt_since_last_improvement = 0\n",
    "for epoch in range(1000):\n",
    "    first = True\n",
    "    print (\"Epoch\", epoch)\n",
    "    sum_loss = 0.0\n",
    "    steps = 0.0\n",
    "    hw.train()\n",
    "    total_ctc_loss = 0.0\n",
    "    count = 0\n",
    "    for i, x in enumerate(train_dataloader):\n",
    "        \n",
    "        \n",
    "        line_imgs = Variable(x['line_imgs'].type(dtype), requires_grad=False)\n",
    "        labels =  Variable(x['labels'], requires_grad=False)\n",
    "        ###MEhreen\n",
    "        #print('....before', labels)\n",
    "        #labels = torch.flip(labels, [0])\n",
    "        #print('....aftr', labels)\n",
    "        ###End mehreen\n",
    "        label_lengths = Variable(x['label_lengths'], requires_grad=False)\n",
    "\n",
    "        preds = hw(line_imgs).cpu()\n",
    "        if torch.any(torch.isnan(line_imgs)):\n",
    "            bd_line_imgs = line_imgs\n",
    "            print('...NAN line_imgs: i, count', i, count)\n",
    "        if torch.any(torch.isnan(preds)):\n",
    "            bd_line_imgs = line_imgs\n",
    "            print('...NAN preds: i, count', i, count)\n",
    "            break\n",
    "        output_batch = preds.permute(1,0,2)\n",
    "        out = output_batch.data.cpu().numpy()\n",
    "\n",
    "        for i, gt_line in enumerate(x['gt']):\n",
    "            logits = out[i,...]\n",
    "            pred, raw_pred = string_utils.naive_decode(logits)\n",
    "            pred_str = string_utils.label2str_single(pred, idx_to_char, False)\n",
    "            cer = error_rates.cer(gt_line, pred_str)\n",
    "            sum_loss += cer\n",
    "            steps += 1\n",
    "\n",
    "\n",
    "        batch_size = preds.size(1)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "\n",
    "        # print \"before\"\n",
    "        loss = criterion(preds, labels, preds_size, label_lengths)\n",
    "        #print('...count', count, 'loss', loss)\n",
    "        total_ctc_loss += loss\n",
    "        #print('preds', preds)\n",
    "        #print('labels', labels)\n",
    "        # print('ctc loss, len(preds), len(labels)', loss, preds.size(), labels.size())\n",
    "        if torch.isnan(loss):\n",
    "            print('...NAN Loss, count', count)\n",
    "            #iimg = line_imgs.cpu()[0].permute(1, 2, 0)\n",
    "            #iimg = (iimg+1)*128\n",
    "            #print('....iimg', iimg.size())\n",
    "            #plt.imshow(iimg)\n",
    "            #plt.show()\n",
    "            #print('NAN LOSS i', i)\n",
    "            #print('preds.size', preds.size())\n",
    "            #print('labels length', label_lengths)\n",
    "            #print('preds', preds)\n",
    "            #print('labels', labels)\n",
    "            #print('line imgs', line_imgs)\n",
    "            break\n",
    "        # print \"after\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if torch.any(torch.isnan(hw.cnn[0].weight)):\n",
    "            print(\"NAN WEIGHT BEFORE BACKWARD\")\n",
    "        #if first:\n",
    "        #    hw2 = pickle.loads(pickle.dumps(hw))\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(hw.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        count = count + 1\n",
    "        \n",
    "    print('....ctc loss', total_ctc_loss)\n",
    "    ### MEhreen add break for one ex\n",
    "    #break\n",
    "    print( \"Train Loss\", sum_loss/steps)\n",
    "    print( \"Real Epoch\", train_dataloader.epoch)\n",
    "    train_loss.append(sum_loss/steps)\n",
    "    ctc_loss.append(total_ctc_loss.item())\n",
    "    \n",
    "    \n",
    "    \n",
    "    sum_loss = 0.0\n",
    "    steps = 0.0\n",
    "    hw.eval()\n",
    "\n",
    "    for x in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            line_imgs = Variable(x['line_imgs'].type(dtype), requires_grad=False)\n",
    "            labels =  Variable(x['labels'], requires_grad=False)\n",
    "            label_lengths = Variable(x['label_lengths'], requires_grad=False)\n",
    "\n",
    "        preds = hw(line_imgs).cpu()\n",
    "\n",
    "        output_batch = preds.permute(1,0,2)\n",
    "        out = output_batch.data.cpu().numpy()\n",
    "\n",
    "        for i, gt_line in enumerate(x['gt']):\n",
    "            logits = out[i,...]\n",
    "            pred, raw_pred = string_utils.naive_decode(logits)\n",
    "            pred_str = string_utils.label2str_single(pred, idx_to_char, False)\n",
    "            cer = error_rates.cer(gt_line, pred_str)\n",
    "            sum_loss += cer\n",
    "            steps += 1\n",
    "\n",
    "    cnt_since_last_improvement += 1\n",
    "    if lowest_loss > sum_loss/steps:\n",
    "        cnt_since_last_improvement = 0\n",
    "        lowest_loss = sum_loss/steps\n",
    "        print (\"Saving Best\")\n",
    "\n",
    "        if not os.path.exists(pretrain_config['snapshot_path']):\n",
    "            os.makedirs(pretrain_config['snapshot_path'])\n",
    "\n",
    "        torch.save(hw.state_dict(), os.path.join(pretrain_config['snapshot_path'], 'hw.pt'))\n",
    "\n",
    "    print(\"Test Loss\", sum_loss/steps, lowest_loss)\n",
    "    valid_loss.append(sum_loss/steps)\n",
    "\n",
    "    if cnt_since_last_improvement >= pretrain_config['hw']['stop_after_no_improvement'] and lowest_loss<0.9:\n",
    "        break\n",
    "print('Done ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adrian\\anaconda3\\python.exe\n",
      "C:\\Users\\Adrian\\anaconda3\\lib\\site-packages\\torch\\__init__.py\n",
      "CUDA Available True\n",
      "Collecting environment information...\n",
      "PyTorch version: 1.10.0\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 11.3\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Microsoft Windows 10 Home\n",
      "GCC version: Could not collect\n",
      "Clang version: Could not collect\n",
      "CMake version: Could not collect\n",
      "Libc version: N/A\n",
      "\n",
      "Python version: 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)] (64-bit runtime)\n",
      "Python platform: Windows-10-10.0.19041-SP0\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.5.119\r\n",
      "GPU models and configuration: Could not collect\n",
      "Nvidia driver version: Could not collect\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.23.4\r\n",
      "[pip3] torch==1.10.0\r\n",
      "[pip3] torchaudio==0.10.0\r\n",
      "[pip3] torchvision==0.11.1\n",
      "[conda] blas                      1.0                         mkl  \r\n",
      "[conda] cudatoolkit               11.3.1               h59b6b97_2  \r\n",
      "[conda] mkl                       2021.4.0           haa95532_640  \r\n",
      "[conda] mkl-service               2.4.0            py38h2bbff1b_0  \r\n",
      "[conda] mkl_fft                   1.3.1            py38h277e83a_0  \r\n",
      "[conda] mkl_random                1.2.2            py38hf11a4ad_0  \r\n",
      "[conda] numpy                     1.22.4                   pypi_0    pypi\r\n",
      "[conda] numpy-base                1.23.4           py38h4da318b_0  \r\n",
      "[conda] pytorch                   1.10.0          py3.8_cuda11.3_cudnn8_0    pytorch\r\n",
      "[conda] pytorch-mutex             1.0                        cuda    pytorch\r\n",
      "[conda] torchaudio                0.10.0               py38_cu113    pytorch\r\n",
      "[conda] torchvision               0.11.1               py38_cu113    pytorch\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import torch\n",
    "print(torch.__file__)\n",
    "print(\"CUDA Available\", torch.cuda.is_available())\n",
    "from torch.utils import collect_env\n",
    "print(collect_env.main())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0424a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "train_stat = {'train_loss': train_loss, 'ctc_loss': ctc_loss, 'valid_loss': valid_loss}\n",
    "\n",
    "\n",
    "strm = csv.writer(open(\"pretrain_hw_log.csv\", \"a\"))\n",
    "for key, val in train_stat.items():\n",
    "    strm.writerow([key, val])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "base",
   "language": "python",
   "display_name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
